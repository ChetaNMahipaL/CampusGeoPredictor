{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from PIL import ImageFilter, ImageEnhance\n",
    "from PIL import Image\n",
    "import math\n",
    "import random\n",
    "from timm.data.mixup import Mixup\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import autoaugment\n",
    "from timm.data import RandAugment\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import csv\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandAugment(num_ops=2, magnitude=9),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ,\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_color = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_affine = T.Compose([\n",
    "    T.Resize((288, 288)),\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    T.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.85, 1.15), shear=10),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def angle_to_vector(theta_deg):\n",
    "    theta_rad = math.radians(theta_deg)\n",
    "    return torch.tensor([math.cos(theta_rad), math.sin(theta_rad)], dtype=torch.float32)\n",
    "\n",
    "def vector_to_angle(vector):\n",
    "    cos_theta, sin_theta = vector\n",
    "    angle_rad = torch.atan2(sin_theta, cos_theta)\n",
    "    angle_deg = angle_rad * (180 / math.pi)\n",
    "    # Ensure angle is in [0, 360) range\n",
    "    return (angle_deg + 360) % 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train & Val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        angle = float(row['angle'])\n",
    "        angle_vector = angle_to_vector(angle)  # (cosθ, sinθ)\n",
    "        return image, angle_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = sorted(os.listdir(image_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Augment Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(image_dir, labels_df):\n",
    "    # Original dataset\n",
    "    original_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_base\n",
    "    )\n",
    "    \n",
    "    # Color jitter augmented dataset\n",
    "    color_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_color\n",
    "    )\n",
    "    \n",
    "    # # Affine transform augmented dataset\n",
    "    affine_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_affine\n",
    "    )\n",
    "    \n",
    "    extended_dataset = ConcatDataset([original_dataset, color_dataset, affine_dataset])\n",
    "    \n",
    "    return extended_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"./Dataset/Train/images_train\"\n",
    "labels_path_train = \"./Dataset/Train/labels_train.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(labels_path_train)\n",
    "\n",
    "train_dataset = create_extended_dataset(image_dir_train, labels_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_val = \"./Dataset/Val/images_val\"\n",
    "labels_path_val = \"./Dataset/Val/labels_val.csv\"\n",
    "labels_df_val = pd.read_csv(labels_path_val)\n",
    "\n",
    "val_dataset = AngleDataset(images_dir_val, labels_df_val, transform_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_test = \"./Dataset/Test\"\n",
    "\n",
    "test_dataset = TestDataset(images_dir_test, transform_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetV3Regressor(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = timm.create_model(\n",
    "            'tf_efficientnetv2_s',\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "        )\n",
    "        \n",
    "        feature_dim = self.base_model.num_features  \n",
    "        \n",
    "        self.vector_branch = nn.Sequential(\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(feature_dim, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = F.interpolate(x, size=(192, 192), mode='bilinear', align_corners=False)        \n",
    "        features = self.base_model(x)\n",
    "        vector_output = self.vector_branch(features)\n",
    "        vector_output = F.normalize(vector_output, p=2, dim=1)\n",
    "        return {'vector': vector_output}\n",
    "\n",
    "class DeitRegressor(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = timm.create_model(\n",
    "            'deit_base_patch16_224',\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "        )\n",
    "        \n",
    "        feature_dim = self.base_model.num_features\n",
    "        \n",
    "        self.vector_branch = nn.Sequential(\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(feature_dim, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        features = self.base_model(x)\n",
    "        vector_output = self.vector_branch(features)\n",
    "        vector_output = F.normalize(vector_output, p=2, dim=1)\n",
    "        return {'vector': vector_output}\n",
    "\n",
    "class TorchvisionEffNetV2Regressor(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        self.base_model = efficientnet_v2_s(weights=weights)\n",
    "        \n",
    "        self.base_model.classifier = nn.Identity()\n",
    "        feature_dim = self.base_model.classifier.in_features if hasattr(self.base_model.classifier, 'in_features') else 1280\n",
    "\n",
    "        self.vector_branch = nn.Sequential(\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(feature_dim, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(192, 192), mode='bilinear', align_corners=False)\n",
    "        features = self.base_model(x)\n",
    "        vector = self.vector_branch(features)\n",
    "        vector = F.normalize(vector, p=2, dim=1)\n",
    "        return {\"vector\": vector}\n",
    "    \n",
    "class GlobalContextModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super().__init__()\n",
    "        self.conv_mask = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "        self.channel_attn = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, channels, height, width = x.size()\n",
    "        \n",
    "        input_x = x\n",
    "        input_x = self.conv_mask(input_x)  # [B, 1, H, W]\n",
    "        input_x = input_x.view(batch, 1, height * width)\n",
    "        attn = self.softmax(input_x)\n",
    "        attn = attn.view(batch, 1, height, width)\n",
    "        \n",
    "        x_weighted = x * attn\n",
    "        \n",
    "        context = torch.sum(x_weighted, dim=(2, 3), keepdim=True) / (height * width)\n",
    "        context = context.view(batch, channels)\n",
    "        \n",
    "        channel_attn = self.channel_attn(context).view(batch, channels, 1, 1)\n",
    "        \n",
    "        return x * channel_attn\n",
    "\n",
    "class FeaturePyramidModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_list, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lateral_convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "            for in_channels in in_channels_list\n",
    "        ])\n",
    "        \n",
    "        self.output_convs = nn.ModuleList([\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "            for _ in range(len(in_channels_list))\n",
    "        ])\n",
    "        \n",
    "    def forward(self, features):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        prev = self.lateral_convs[-1](features[-1])\n",
    "        results.append(self.output_convs[-1](prev))\n",
    "        \n",
    "        for i in range(len(features) - 2, -1, -1):\n",
    "\n",
    "            current = self.lateral_convs[i](features[i])\n",
    "            \n",
    "            prev_shape = prev.shape[2:]\n",
    "            current_shape = current.shape[2:]\n",
    "            \n",
    "            if prev_shape[0] < current_shape[0] or prev_shape[1] < current_shape[1]:\n",
    "                prev = F.interpolate(prev, size=current_shape, mode='bilinear', align_corners=False)\n",
    "            \n",
    "            prev = current + prev\n",
    "            results.append(self.output_convs[i](prev))\n",
    "        \n",
    "        return list(reversed(results))\n",
    "\n",
    "class SelfAttention2D(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.query = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.key = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.value = nn.Conv2d(in_dim, in_dim, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        proj_query = self.query(x).view(B, -1, H * W).permute(0, 2, 1)  # [B, N, C']\n",
    "        proj_key = self.key(x).view(B, -1, H * W)                       # [B, C', N]\n",
    "        energy = torch.bmm(proj_query, proj_key)                       # [B, N, N]\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        proj_value = self.value(x).view(B, -1, H * W)                  # [B, C, N]\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))       # [B, C, N]\n",
    "        out = out.view(B, C, H, W)\n",
    "        return self.gamma * out + x\n",
    "    \n",
    "class EfficientNetV2Regressor(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.2, use_fpn=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = timm.create_model(\n",
    "            'tf_efficientnetv2_s', \n",
    "            pretrained=pretrained,\n",
    "            features_only=True,\n",
    "            out_indices=(2, 3, 4)\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "            features = self.base_model(dummy_input)\n",
    "            feature_channels = [feat.shape[1] for feat in features]\n",
    "            print(f\"Actual feature channels: {feature_channels}\")\n",
    "        \n",
    "        self.use_fpn = use_fpn\n",
    "        if use_fpn:\n",
    "            self.fpn = FeaturePyramidModule(feature_channels, 256)\n",
    "            merged_channels = 256\n",
    "        else:\n",
    "            merged_channels = feature_channels[-1]\n",
    "\n",
    "        self.attention = SelfAttention2D(merged_channels)        \n",
    "        self.gc_module = GlobalContextModule(merged_channels)\n",
    "        \n",
    "        self.vector_branch = nn.Sequential(\n",
    "            nn.Linear(merged_channels, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            \n",
    "            nn.Linear(256, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "        \n",
    "        self.bin_branch = nn.Sequential(\n",
    "            nn.Linear(merged_channels, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.Linear(128, 36)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        features = self.base_model(x)\n",
    "        \n",
    "        if self.use_fpn:\n",
    "            processed_features = self.fpn(features)\n",
    "            feat = processed_features[0]\n",
    "        else:\n",
    "            feat = features[-1]\n",
    "\n",
    "        feat = self.attention(feat)\n",
    "        feat = self.gc_module(feat)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(feat, 1).flatten(1)\n",
    "        \n",
    "        vector_output = self.vector_branch(x)\n",
    "        bin_logits = self.bin_branch(x)\n",
    "        \n",
    "        vector_output = F.normalize(vector_output, p=2, dim=1)\n",
    "        \n",
    "        return {\n",
    "            'vector': vector_output,\n",
    "            'bin_logits': bin_logits\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        y_pred_normalized = y_pred / torch.norm(y_pred, dim=1, keepdim=True)\n",
    "        y_true_normalized = y_true / torch.norm(y_true, dim=1, keepdim=True)\n",
    "        \n",
    "        cos_angle_diff = torch.sum(y_pred_normalized * y_true_normalized, dim=1)\n",
    "        \n",
    "        cos_angle_diff = torch.clamp(cos_angle_diff, -1.0 + 1e-7, 1.0 - 1e-7)\n",
    "        \n",
    "        angle_loss = 1.0 - cos_angle_diff\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return angle_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return angle_loss.sum()\n",
    "        else:\n",
    "            return angle_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    angle_errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs['vector']\n",
    "            \n",
    "            for i in range(outputs.size(0)):\n",
    "                true_angle = vector_to_angle(labels[i]).item()\n",
    "                pred_angle = vector_to_angle(outputs[i]).item()\n",
    "\n",
    "                # Normalize angles to [0, 360)\n",
    "                true_angle = true_angle % 360\n",
    "                pred_angle = pred_angle % 360\n",
    "                \n",
    "                angle_diff = abs(true_angle - pred_angle)\n",
    "                angle_diff = min(angle_diff, 360 - angle_diff)\n",
    "                \n",
    "                predictions.append(pred_angle)\n",
    "                ground_truths.append(true_angle)\n",
    "                angle_errors.append(angle_diff)\n",
    "    \n",
    "    mean_angle_error = sum(angle_errors) / len(angle_errors)\n",
    "    median_angle_error = sorted(angle_errors)[len(angle_errors) // 2]\n",
    "    \n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        pred_rad = math.radians(predictions[i])\n",
    "        true_rad = math.radians(ground_truths[i])\n",
    "        \n",
    "        pred_sin, pred_cos = math.sin(pred_rad), math.cos(pred_rad)\n",
    "        true_sin, true_cos = math.sin(true_rad), math.cos(true_rad)\n",
    "        \n",
    "        mse += (pred_sin - true_sin)**2 + (pred_cos - true_cos)**2\n",
    "    \n",
    "    mse /= len(predictions)\n",
    "    \n",
    "    results = {\n",
    "        'mean_angle_error': mean_angle_error,\n",
    "        'median_angle_error': median_angle_error,\n",
    "        'mse_sin_cos': mse,\n",
    "        'predictions': predictions,\n",
    "        'ground_truths': ground_truths,\n",
    "        'angle_errors': angle_errors\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(model, train_loader, val_loader, optimizer, num_epochs, device, loss_fn):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = outputs['vector']\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for images, targets in pbar:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                preds = outputs['vector']\n",
    "                loss = loss_fn(preds, targets)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Optional: you can compute angle error for logging\n",
    "        results = evaluate_model(model, val_loader, device)\n",
    "        val_mae = results['mean_angle_error']\n",
    "\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train MSE = {avg_train_loss:.4f}, Val MSE = {avg_val_loss:.4f}, Val MAE = {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeitRegressor(pretrained=True, dropout_rate=0.2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.05)\n",
    "loss_fn = AngleLoss(reduction='mean')\n",
    "    \n",
    "\n",
    "# Train\n",
    "train_regression_model(model, train_loader, val_loader, optimizer,\n",
    "                      num_epochs=100, device=device, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetV2Regressor(pretrained=True,dropout_rate=0.2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train\n",
    "train_regression_model(model, train_loader, val_loader, optimizer,\n",
    "                       num_epochs=20, device=device, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_model(model, val_loader, device)\n",
    "print(f\"Mean Angle Error: {results['mean_angle_error']:.4f} degrees\")\n",
    "print(f\"Median Angle Error: {results['median_angle_error']:.4f} degrees\")\n",
    "print(f\"MSE (sin/cos): {results['mse_sin_cos']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_angles_ensemble(models, val_loader, test_loader, device):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    predicted_angles = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Validation predictions\n",
    "        for inputs, _ in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            summed_outputs = torch.zeros(inputs.size(0), 2).to(device)\n",
    "\n",
    "            for model in models:\n",
    "                outputs = model(inputs)\n",
    "                summed_outputs += outputs['vector']\n",
    "\n",
    "            avg_outputs = summed_outputs / len(models)\n",
    "\n",
    "            for output in avg_outputs:\n",
    "                angle = vector_to_angle(output).item()\n",
    "                predicted_angles.append(angle % 360)\n",
    "\n",
    "        assert len(predicted_angles) == 369, f\"Expected 369 val predictions, got {len(predicted_angles)}\"\n",
    "\n",
    "        # Test predictions\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            summed_outputs = torch.zeros(inputs.size(0), 2).to(device)\n",
    "\n",
    "            for model in models:\n",
    "                outputs = model(inputs)\n",
    "                summed_outputs += outputs['vector']\n",
    "\n",
    "            avg_outputs = summed_outputs / len(models)\n",
    "\n",
    "            for output in avg_outputs:\n",
    "                angle = vector_to_angle(output).item()\n",
    "                predicted_angles.append(angle % 360)\n",
    "\n",
    "        assert len(predicted_angles) == 738, f\"Expected 738 total predictions, got {len(predicted_angles)}\"\n",
    "\n",
    "    return predicted_angles\n",
    "\n",
    "\n",
    "def create_submission_csv(predicted_angles, roll_number='2022101001', version='3'):\n",
    "    filename = f\"{roll_number}_{version}.csv\"\n",
    "    \n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['id', 'angle'])  # Header\n",
    "\n",
    "        for idx, angle in enumerate(predicted_angles):\n",
    "            writer.writerow([idx, angle % 360])\n",
    "\n",
    "    print(f\"Submission CSV saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(models, test_loader, device):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    angle_errors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Sum the output vectors from all models\n",
    "            summed_outputs = torch.zeros(labels.size(0), 2).to(device)\n",
    "            for model in models:\n",
    "                outputs = model(inputs)\n",
    "                summed_outputs += outputs['vector']\n",
    "\n",
    "            # Average the outputs\n",
    "            avg_outputs = summed_outputs / len(models)\n",
    "\n",
    "            for i in range(avg_outputs.size(0)):\n",
    "                true_angle = vector_to_angle(labels[i]).item()\n",
    "                pred_angle = vector_to_angle(avg_outputs[i]).item()\n",
    "\n",
    "                # Normalize angles to [0, 360)\n",
    "                true_angle = true_angle % 360\n",
    "                pred_angle = pred_angle % 360\n",
    "\n",
    "                angle_diff = abs(true_angle - pred_angle)\n",
    "                angle_diff = min(angle_diff, 360 - angle_diff)\n",
    "\n",
    "                predictions.append(pred_angle)\n",
    "                ground_truths.append(true_angle)\n",
    "                angle_errors.append(angle_diff)\n",
    "\n",
    "    mean_angle_error = sum(angle_errors) / len(angle_errors)\n",
    "    median_angle_error = sorted(angle_errors)[len(angle_errors) // 2]\n",
    "\n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        pred_rad = math.radians(predictions[i])\n",
    "        true_rad = math.radians(ground_truths[i])\n",
    "\n",
    "        pred_sin, pred_cos = math.sin(pred_rad), math.cos(pred_rad)\n",
    "        true_sin, true_cos = math.sin(true_rad), math.cos(true_rad)\n",
    "\n",
    "        mse += (pred_sin - true_sin) ** 2 + (pred_cos - true_cos) ** 2\n",
    "\n",
    "    mse /= len(predictions)\n",
    "\n",
    "    results = {\n",
    "        'mean_angle_error': mean_angle_error,\n",
    "        'median_angle_error': median_angle_error,\n",
    "        'mse_sin_cos': mse,\n",
    "        'predictions': predictions,\n",
    "        'ground_truths': ground_truths,\n",
    "        'angle_errors': angle_errors\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Load the models\n",
    "model_eff_ev = EfficientNetV2Regressor(pretrained=False)\n",
    "model_eff_ev.to(device)\n",
    "model_deit_ev = EfficientNetV3Regressor(pretrained=False)\n",
    "model_deit_ev.to(device)\n",
    "model_deit2_ev = DeitRegressor(pretrained=False)\n",
    "model_deit2_ev.to(device)\n",
    "model_fpn_ev = EfficientNetV2Regressor(pretrained=False, dropout_rate=0.2, use_fpn=True)\n",
    "model_fpn_ev.to(device)\n",
    "\n",
    "# Load the ensemble model\n",
    "checkpoint = torch.load('./ensemble_model_4.pth')\n",
    "model_eff_ev.load_state_dict(checkpoint['model_eff'])\n",
    "model_deit_ev.load_state_dict(checkpoint['model_deit'])\n",
    "model_deit2_ev.load_state_dict(checkpoint['model_deit2'])\n",
    "model_fpn_ev.load_state_dict(checkpoint['model_fpn'])\n",
    "\n",
    "\n",
    "results = evaluate_ensemble([model_deit_ev, model_deit2_ev, model_eff_ev, model_fpn_ev], val_loader, device)\n",
    "print(f\"Mean Angle Error: {results['mean_angle_error']:.4f} degrees\")\n",
    "ensemble_predictions = get_predicted_angles_ensemble([model_deit_ev, model_deit2_ev, model_eff_ev, model_fpn_ev], val_loader, test_loader, device)\n",
    "create_submission_csv(ensemble_predictions, roll_number='2022101096', version='9')\n",
    "# # Save the ensemble model\n",
    "# ensemble_model_path = 'ensemble_model_4.pth'\n",
    "# torch.save({\n",
    "#     'model_eff': model_eff_ev.state_dict(),\n",
    "#     'model_deit': model_deit_ev.state_dict(),\n",
    "#     'model_deit2': model_deit2_ev.state_dict(),\n",
    "#     'model_fpn': model_fpn_ev.state_dict(),\n",
    "# }, ensemble_model_path)\n",
    "# print(f\"Ensemble model saved as: {ensemble_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_storysumm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
