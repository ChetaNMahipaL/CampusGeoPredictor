{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_color = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_affine = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def angle_to_vector(theta_deg):\n",
    "    theta_rad = math.radians(theta_deg)\n",
    "    return torch.tensor([math.cos(theta_rad), math.sin(theta_rad)], dtype=torch.float32)\n",
    "\n",
    "def vector_to_angle(vector):\n",
    "    cos_theta, sin_theta = vector\n",
    "    angle_rad = torch.atan2(sin_theta, cos_theta)\n",
    "    angle_deg = angle_rad * (180 / math.pi)\n",
    "    # Ensure angle is in [0, 360) range\n",
    "    return (angle_deg + 360) % 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        angle = float(row['angle'])\n",
    "        angle_vector = angle_to_vector(angle)  # (cosθ, sinθ)\n",
    "        return image, angle_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extend Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(image_dir, labels_df):\n",
    "    # Original dataset\n",
    "    original_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_base\n",
    "    )\n",
    "    \n",
    "    # Color jitter augmented dataset\n",
    "    color_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_color\n",
    "    )\n",
    "    \n",
    "    # # Affine transform augmented dataset\n",
    "    affine_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_affine\n",
    "    )\n",
    "    \n",
    "    extended_dataset = ConcatDataset([original_dataset, color_dataset, affine_dataset])\n",
    "    \n",
    "    return extended_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"Dataset/Train/images_train\"\n",
    "labels_path_train = \"Dataset/Train/labels_train.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(labels_path_train)\n",
    "\n",
    "train_dataset = create_extended_dataset(image_dir_train, labels_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_val = \"Dataset/Val/images_val\"\n",
    "labels_path_val = \"Dataset/Val/labels_val.csv\"\n",
    "labels_df_val = pd.read_csv(labels_path_val)\n",
    "\n",
    "val_dataset = AngleDataset(images_dir_val, labels_df_val, transform_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAngleRegressor(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet50(weights='DEFAULT' if pretrained else None)\n",
    "        num_features = base_model.fc.in_features\n",
    "        # Remove the final fully connected layer\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        \n",
    "        # New regression head with dropout and batch normalization\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.BatchNorm1d(512), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.regressor(x)\n",
    "        # Normalize output to enforce unit vector\n",
    "        return x / torch.norm(x, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        y_pred_normalized = y_pred / torch.norm(y_pred, dim=1, keepdim=True)\n",
    "        y_true_normalized = y_true / torch.norm(y_true, dim=1, keepdim=True)\n",
    "        \n",
    "        cos_angle_diff = torch.sum(y_pred_normalized * y_true_normalized, dim=1)\n",
    "        \n",
    "        cos_angle_diff = torch.clamp(cos_angle_diff, -1.0 + 1e-7, 1.0 - 1e-7)\n",
    "        \n",
    "        angle_loss = 1.0 - cos_angle_diff\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return angle_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return angle_loss.sum()\n",
    "        else:\n",
    "            return angle_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(model, train_loader, val_loader, optimizer, num_epochs, device, loss_fn):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)  # shape: (batch_size, 2)\n",
    "\n",
    "            preds = model(images)  # output shape: (batch_size, 2)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for images, targets in pbar:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                preds = model(images)\n",
    "                loss = loss_fn(preds, targets)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train MSE = {avg_train_loss:.4f}, Val MSE = {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    angle_errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            for i in range(outputs.size(0)):\n",
    "                true_angle = vector_to_angle(labels[i]).item()\n",
    "                pred_angle = vector_to_angle(outputs[i]).item()\n",
    "\n",
    "                # Normalize angles to [0, 360)\n",
    "                true_angle = true_angle % 360\n",
    "                pred_angle = pred_angle % 360\n",
    "                \n",
    "                angle_diff = abs(true_angle - pred_angle)\n",
    "                angle_diff = min(angle_diff, 360 - angle_diff)\n",
    "                \n",
    "                predictions.append(pred_angle)\n",
    "                ground_truths.append(true_angle)\n",
    "                angle_errors.append(angle_diff)\n",
    "    \n",
    "    mean_angle_error = sum(angle_errors) / len(angle_errors)\n",
    "    median_angle_error = sorted(angle_errors)[len(angle_errors) // 2]\n",
    "    \n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        pred_rad = math.radians(predictions[i])\n",
    "        true_rad = math.radians(ground_truths[i])\n",
    "        \n",
    "        pred_sin, pred_cos = math.sin(pred_rad), math.cos(pred_rad)\n",
    "        true_sin, true_cos = math.sin(true_rad), math.cos(true_rad)\n",
    "        \n",
    "        mse += (pred_sin - true_sin)**2 + (pred_cos - true_cos)**2\n",
    "    \n",
    "    mse /= len(predictions)\n",
    "    \n",
    "    results = {\n",
    "        'mean_angle_error': mean_angle_error,\n",
    "        'median_angle_error': median_angle_error,\n",
    "        'mse_sin_cos': mse,\n",
    "        'predictions': predictions,\n",
    "        'ground_truths': ground_truths,\n",
    "        'angle_errors': angle_errors\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 1227/1227 [06:18<00:00,  3.24it/s, loss=0.975]\n",
      "Epoch 1/20 [Val]: 100%|██████████| 24/24 [00:03<00:00,  7.99it/s, loss=0.211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE = 0.9025, Val MSE = 0.8121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 1227/1227 [06:15<00:00,  3.27it/s, loss=0.806]\n",
      "Epoch 2/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.21it/s, loss=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train MSE = 0.7609, Val MSE = 0.7365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 1227/1227 [06:15<00:00,  3.27it/s, loss=0.568]\n",
      "Epoch 3/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.23it/s, loss=0.00322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train MSE = 0.6588, Val MSE = 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 1227/1227 [06:15<00:00,  3.27it/s, loss=0.644]\n",
      "Epoch 4/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.22it/s, loss=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train MSE = 0.5777, Val MSE = 0.5946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 1227/1227 [05:58<00:00,  3.42it/s, loss=0.6]  \n",
      "Epoch 5/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.72it/s, loss=0.0749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train MSE = 0.5092, Val MSE = 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 1227/1227 [05:52<00:00,  3.48it/s, loss=0.353]\n",
      "Epoch 6/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.70it/s, loss=0.0589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train MSE = 0.4528, Val MSE = 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 1227/1227 [06:14<00:00,  3.28it/s, loss=0.667] \n",
      "Epoch 7/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.09it/s, loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train MSE = 0.4003, Val MSE = 0.5442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.25it/s, loss=0.269] \n",
      "Epoch 8/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.20it/s, loss=0.0215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train MSE = 0.3568, Val MSE = 0.5297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.32]  \n",
      "Epoch 9/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.23it/s, loss=0.00621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train MSE = 0.3205, Val MSE = 0.5128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.152] \n",
      "Epoch 10/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.18it/s, loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train MSE = 0.2834, Val MSE = 0.4815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.211] \n",
      "Epoch 11/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.22it/s, loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train MSE = 0.2531, Val MSE = 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.375] \n",
      "Epoch 12/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.16it/s, loss=0.0207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train MSE = 0.2273, Val MSE = 0.4680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.0658]\n",
      "Epoch 13/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.21it/s, loss=0.00658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train MSE = 0.2051, Val MSE = 0.4274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.189] \n",
      "Epoch 14/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.14it/s, loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train MSE = 0.1890, Val MSE = 0.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.189] \n",
      "Epoch 15/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.19it/s, loss=0.000594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train MSE = 0.1750, Val MSE = 0.4092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 1227/1227 [06:15<00:00,  3.27it/s, loss=0.148] \n",
      "Epoch 16/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.20it/s, loss=0.0618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train MSE = 0.1616, Val MSE = 0.4089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 1227/1227 [06:15<00:00,  3.26it/s, loss=0.493] \n",
      "Epoch 17/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.23it/s, loss=0.0615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train MSE = 0.1438, Val MSE = 0.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 1227/1227 [06:07<00:00,  3.34it/s, loss=0.0525]\n",
      "Epoch 18/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.52it/s, loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train MSE = 0.1423, Val MSE = 0.3521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 1227/1227 [06:15<00:00,  3.27it/s, loss=0.258] \n",
      "Epoch 19/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.18it/s, loss=0.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train MSE = 0.1266, Val MSE = 0.3653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 1227/1227 [06:16<00:00,  3.26it/s, loss=0.114] \n",
      "Epoch 20/20 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.18it/s, loss=0.00972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train MSE = 0.1209, Val MSE = 0.3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNetAngleRegressor()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "train_regression_model(model, train_loader, val_loader, optimizer, num_epochs=20, device=device, loss_fn=loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Angle Error: 41.5600 degrees\n",
      "Median Angle Error: 26.8624 degrees\n",
      "MSE (sin/cos): 0.7301\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = evaluate_model(model, val_loader, device)\n",
    "print(f\"Mean Angle Error: {results['mean_angle_error']:.4f} degrees\")\n",
    "print(f\"Median Angle Error: {results['median_angle_error']:.4f} degrees\")\n",
    "print(f\"MSE (sin/cos): {results['mse_sin_cos']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
