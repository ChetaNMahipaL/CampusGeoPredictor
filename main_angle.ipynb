{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from PIL import ImageFilter, ImageEnhance\n",
    "from PIL import Image\n",
    "import math\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ,\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_color = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_affine = T.Compose([\n",
    "    T.Resize((288, 288)),\n",
    "    T.RandomResizedCrop(256, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    T.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.85, 1.15), shear=10),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def angle_to_vector(theta_deg):\n",
    "    theta_rad = math.radians(theta_deg)\n",
    "    return torch.tensor([math.cos(theta_rad), math.sin(theta_rad)], dtype=torch.float32)\n",
    "\n",
    "def vector_to_angle(vector):\n",
    "    cos_theta, sin_theta = vector\n",
    "    angle_rad = torch.atan2(sin_theta, cos_theta)\n",
    "    angle_deg = angle_rad * (180 / math.pi)\n",
    "    # Ensure angle is in [0, 360) range\n",
    "    return (angle_deg + 360) % 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        angle = float(row['angle'])\n",
    "        angle_vector = angle_to_vector(angle)  # (cosθ, sinθ)\n",
    "        return image, angle_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(image_dir, labels_df):\n",
    "    # Original dataset\n",
    "    original_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_base\n",
    "    )\n",
    "    \n",
    "    # Color jitter augmented dataset\n",
    "    color_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_color\n",
    "    )\n",
    "    \n",
    "    # # Affine transform augmented dataset\n",
    "    affine_dataset = AngleDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_affine\n",
    "    )\n",
    "    \n",
    "    extended_dataset = ConcatDataset([original_dataset, color_dataset, affine_dataset])\n",
    "    \n",
    "    return extended_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"Dataset/Train/images_train\"\n",
    "labels_path_train = \"Dataset/Train/labels_train.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(labels_path_train)\n",
    "\n",
    "train_dataset = create_extended_dataset(image_dir_train, labels_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_val = \"Dataset/Val/images_val\"\n",
    "labels_path_val = \"Dataset/Val/labels_val.csv\"\n",
    "labels_df_val = pd.read_csv(labels_path_val)\n",
    "\n",
    "val_dataset = AngleDataset(images_dir_val, labels_df_val, transform_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAngleRegressor(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet50(weights='DEFAULT' if pretrained else None)\n",
    "        num_features = base_model.fc.in_features\n",
    "        # Remove the final fully connected layer\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        \n",
    "        # New regression head with dropout and batch normalization\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.BatchNorm1d(1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # nn.Linear(512, 256),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(1024, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.regressor(x)\n",
    "        # Normalize output to enforce unit vector\n",
    "        return x / torch.norm(x, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        y_pred_normalized = y_pred / torch.norm(y_pred, dim=1, keepdim=True)\n",
    "        y_true_normalized = y_true / torch.norm(y_true, dim=1, keepdim=True)\n",
    "        \n",
    "        cos_angle_diff = torch.sum(y_pred_normalized * y_true_normalized, dim=1)\n",
    "        \n",
    "        cos_angle_diff = torch.clamp(cos_angle_diff, -1.0 + 1e-7, 1.0 - 1e-7)\n",
    "        \n",
    "        angle_loss = 1.0 - cos_angle_diff\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return angle_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return angle_loss.sum()\n",
    "        else:\n",
    "            return angle_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(model, train_loader, val_loader, optimizer, num_epochs, device, loss_fn):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)  # shape: (batch_size, 2)\n",
    "\n",
    "            preds = model(images)  # output shape: (batch_size, 2)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for images, targets in pbar:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                preds = model(images)\n",
    "                loss = loss_fn(preds, targets)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train MSE = {avg_train_loss:.4f}, Val MSE = {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    angle_errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            for i in range(outputs.size(0)):\n",
    "                true_angle = vector_to_angle(labels[i]).item()\n",
    "                pred_angle = vector_to_angle(outputs[i]).item()\n",
    "\n",
    "                # Normalize angles to [0, 360)\n",
    "                true_angle = true_angle % 360\n",
    "                pred_angle = pred_angle % 360\n",
    "                \n",
    "                angle_diff = abs(true_angle - pred_angle)\n",
    "                angle_diff = min(angle_diff, 360 - angle_diff)\n",
    "                \n",
    "                predictions.append(pred_angle)\n",
    "                ground_truths.append(true_angle)\n",
    "                angle_errors.append(angle_diff)\n",
    "    \n",
    "    mean_angle_error = sum(angle_errors) / len(angle_errors)\n",
    "    median_angle_error = sorted(angle_errors)[len(angle_errors) // 2]\n",
    "    \n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        pred_rad = math.radians(predictions[i])\n",
    "        true_rad = math.radians(ground_truths[i])\n",
    "        \n",
    "        pred_sin, pred_cos = math.sin(pred_rad), math.cos(pred_rad)\n",
    "        true_sin, true_cos = math.sin(true_rad), math.cos(true_rad)\n",
    "        \n",
    "        mse += (pred_sin - true_sin)**2 + (pred_cos - true_cos)**2\n",
    "    \n",
    "    mse /= len(predictions)\n",
    "    \n",
    "    results = {\n",
    "        'mean_angle_error': mean_angle_error,\n",
    "        'median_angle_error': median_angle_error,\n",
    "        'mse_sin_cos': mse,\n",
    "        'predictions': predictions,\n",
    "        'ground_truths': ground_truths,\n",
    "        'angle_errors': angle_errors\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/75 [Train]: 100%|██████████| 1227/1227 [06:30<00:00,  3.15it/s, loss=1]    \n",
      "Epoch 1/75 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s, loss=1.78] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE = 0.8923, Val MSE = 0.7920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/75 [Train]: 100%|██████████| 1227/1227 [06:32<00:00,  3.13it/s, loss=0.525]\n",
      "Epoch 2/75 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.06it/s, loss=0.00404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train MSE = 0.7639, Val MSE = 0.6976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/75 [Train]:  90%|████████▉ | 1102/1227 [06:05<00:43,  2.86it/s, loss=0.694]"
     ]
    }
   ],
   "source": [
    "model = ResNetAngleRegressor()\n",
    "loss_fn = AngleLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "train_regression_model(model, train_loader, val_loader, optimizer, num_epochs=75, device=device, loss_fn=loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = evaluate_model(model, val_loader, device)\n",
    "print(f\"Mean Angle Error: {results['mean_angle_error']:.4f} degrees\")\n",
    "print(f\"Median Angle Error: {results['median_angle_error']:.4f} degrees\")\n",
    "print(f\"MSE (sin/cos): {results['mse_sin_cos']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model for evaluation\n",
    "\n",
    "model_ev = ResNetAngleRegressor()\n",
    "model_ev.to(device)\n",
    "model_ev.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "results = evaluate_model(model_ev, val_loader, device)\n",
    "print(f\"Mean Angle Error: {results['mean_angle_error']:.4f} degrees\")\n",
    "print(f\"Median Angle Error: {results['median_angle_error']:.4f} degrees\")\n",
    "print(f\"MSE (sin/cos): {results['mse_sin_cos']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
