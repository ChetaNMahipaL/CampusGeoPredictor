{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from PIL import ImageFilter, ImageEnhance\n",
    "from PIL import Image\n",
    "import math\n",
    "import random\n",
    "from timm.data.mixup import Mixup\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ,\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_color = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_affine = T.Compose([\n",
    "    T.Resize((288, 288)),\n",
    "    T.RandomResizedCrop(256, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    T.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.85, 1.15), shear=10),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            region = int(row['Region_ID'])\n",
    "            region = region - 1\n",
    "\n",
    "        # Convert to tensor with proper dtype (long) for classification tasks\n",
    "        region_tensor = torch.tensor(region, dtype=torch.long)\n",
    "        \n",
    "        return image, region_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(image_dir, labels_df):\n",
    "    # Original dataset\n",
    "    original_dataset = RegionDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_base\n",
    "    )\n",
    "    \n",
    "    # Color jitter augmented dataset\n",
    "    color_dataset = RegionDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_color\n",
    "    )\n",
    "    \n",
    "    # # Affine transform augmented dataset\n",
    "    affine_dataset = RegionDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_affine\n",
    "    )\n",
    "    \n",
    "    extended_dataset = ConcatDataset([original_dataset, color_dataset, affine_dataset])\n",
    "    \n",
    "    return extended_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"Dataset/Train/images_train\"\n",
    "labels_path_train = \"Dataset/Train/labels_train.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(labels_path_train)\n",
    "\n",
    "train_dataset = create_extended_dataset(image_dir_train, labels_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_val = \"Dataset/Val/images_val\"\n",
    "labels_path_val = \"Dataset/Val/labels_val.csv\"\n",
    "labels_df_val = pd.read_csv(labels_path_val)\n",
    "\n",
    "val_dataset = RegionDataset(images_dir_val, labels_df_val, transform_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetRegionClassifier(nn.Module):\n",
    "    def __init__(self, num_regions=8, pretrained=True, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet50(weights='DEFAULT' if pretrained else None)\n",
    "        num_features = base_model.fc.in_features\n",
    "\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.BatchNorm1d(1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(512, num_regions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_fn = Mixup(\n",
    "    mixup_alpha=0.8, cutmix_alpha=1.0, cutmix_minmax=None,\n",
    "    prob=0.8, switch_prob=0.3, mode='batch',\n",
    "    label_smoothing=0.1, num_classes=15\n",
    ")\n",
    "\n",
    "def train_classification_model(model, train_loader, val_loader, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for images, targets in pbar:\n",
    "            images, targets = mixup_fn(images, targets)\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device) \n",
    "\n",
    "            logits = model(images)\n",
    "\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if len(targets.shape) == 1:\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                correct_train = (preds == targets).sum().item()\n",
    "                total_train = targets.size(0)\n",
    "            else:\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                _, target_labels = torch.max(targets, dim=1) \n",
    "                correct_train = (preds == target_labels).sum().item()\n",
    "                total_train = targets.size(0)\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pbar.set_postfix(loss=loss.item(), acc=f\"{100*correct_train/total_train:.2f}%\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for images, targets in pbar:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                logits = model(images)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total_val += targets.size(0)\n",
    "                correct_val += (predicted == targets).sum().item()\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                pbar.set_postfix(loss=loss.item(), acc=f\"{100*correct_val/total_val:.2f}%\")\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Train Acc = {train_accuracy:.2f}%, \\\n",
    "                Val Loss = {avg_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(model, test_loader, device, num_regions=15):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_ground_truths = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    confusion_matrix = torch.zeros(num_regions, num_regions)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_ground_truths.extend(labels.cpu().numpy())\n",
    "            \n",
    "            for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    per_class_accuracy = confusion_matrix.diag() / confusion_matrix.sum(1)\n",
    "    per_class_accuracy = per_class_accuracy.cpu().numpy()\n",
    "    \n",
    "    adjacent_correct = 0\n",
    "    for i in range(len(all_predictions)):\n",
    "        pred = all_predictions[i]\n",
    "        true = all_ground_truths[i]\n",
    "\n",
    "        if pred == true or (pred == (true + 1) % num_regions) or (pred == (true - 1) % num_regions):\n",
    "            adjacent_correct += 1\n",
    "    \n",
    "    adjacent_accuracy = 100 * adjacent_correct / total\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'adjacent_accuracy': adjacent_accuracy,\n",
    "        'per_class_accuracy': per_class_accuracy,\n",
    "        'predictions': all_predictions,\n",
    "        'ground_truths': all_ground_truths\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1227/1227 [06:42<00:00,  3.05it/s, acc=60.00%, loss=2.34]  \n",
      "Epoch 1/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.07it/s, acc=84.82%, loss=0.475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.9096, Train Acc = 60.00%,                 Val Loss = 0.6378, Val Acc = 84.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1227/1227 [06:49<00:00,  3.00it/s, acc=90.00%, loss=1.04]  \n",
      "Epoch 2/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.09it/s, acc=89.70%, loss=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 1.5354, Train Acc = 90.00%,                 Val Loss = 0.4895, Val Acc = 89.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1227/1227 [06:54<00:00,  2.96it/s, acc=90.00%, loss=0.755] \n",
      "Epoch 3/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.00it/s, acc=91.33%, loss=0.491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 1.3959, Train Acc = 90.00%,                 Val Loss = 0.4805, Val Acc = 91.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1227/1227 [06:49<00:00,  3.00it/s, acc=100.00%, loss=0.63] \n",
      "Epoch 4/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.07it/s, acc=92.41%, loss=0.292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 1.3617, Train Acc = 100.00%,                 Val Loss = 0.4213, Val Acc = 92.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1227/1227 [06:48<00:00,  3.00it/s, acc=90.00%, loss=1.74]  \n",
      "Epoch 5/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.08it/s, acc=92.95%, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 1.2938, Train Acc = 90.00%,                 Val Loss = 0.4149, Val Acc = 92.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 1227/1227 [06:48<00:00,  3.00it/s, acc=100.00%, loss=0.615]\n",
      "Epoch 6/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.10it/s, acc=93.50%, loss=0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 1.2722, Train Acc = 100.00%,                 Val Loss = 0.3939, Val Acc = 93.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 1227/1227 [06:48<00:00,  3.00it/s, acc=40.00%, loss=2.18]  \n",
      "Epoch 7/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.13it/s, acc=93.50%, loss=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 1.2595, Train Acc = 40.00%,                 Val Loss = 0.3880, Val Acc = 93.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 1227/1227 [06:44<00:00,  3.03it/s, acc=80.00%, loss=1.89]  \n",
      "Epoch 8/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.16it/s, acc=94.85%, loss=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 1.2452, Train Acc = 80.00%,                 Val Loss = 0.3863, Val Acc = 94.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 1227/1227 [06:44<00:00,  3.03it/s, acc=100.00%, loss=0.778]\n",
      "Epoch 9/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.13it/s, acc=93.22%, loss=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 1.2426, Train Acc = 100.00%,                 Val Loss = 0.4160, Val Acc = 93.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 1227/1227 [06:49<00:00,  2.99it/s, acc=90.00%, loss=1.59]  \n",
      "Epoch 10/10 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.05it/s, acc=94.58%, loss=0.276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 1.2214, Train Acc = 90.00%,                 Val Loss = 0.4010, Val Acc = 94.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNetRegionClassifier(num_regions=15, pretrained=True, dropout_rate=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 10\n",
    "train_classification_model(model, train_loader, val_loader, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.58%\n",
      "Adjacent Accuracy: 98.64%\n",
      "Per-Class Accuracy: [1.         0.85714287 0.962963   1.         1.         0.9259259\n",
      " 0.9583333  1.         0.6666667  0.969697   0.9583333  0.8888889\n",
      " 0.9583333  1.         0.9444444 ]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = evaluate_classification_model(model, val_loader, device)\n",
    "print(f\"Validation Accuracy: {results['accuracy']:.2f}%\")\n",
    "print(f\"Adjacent Accuracy: {results['adjacent_accuracy']:.2f}%\")\n",
    "print(f\"Per-Class Accuracy: {results['per_class_accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 94.85%\n",
      "Adjacent Accuracy: 98.10%\n",
      "Per-Class Accuracy: [0.95238096 0.95238096 0.962963   0.962963   1.         0.962963\n",
      " 0.9166667  0.962963   0.73333335 0.93939394 0.9583333  0.9259259\n",
      " 0.9583333  1.         0.9722222 ]\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for evaluation\n",
    "\n",
    "model_ev = ResNetRegionClassifier(num_regions=15, pretrained=True, dropout_rate=0.1)\n",
    "model_ev.to(device)\n",
    "model_ev.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "results = evaluate_classification_model(model_ev, val_loader, device)\n",
    "print(f\"Validation Accuracy: {results['accuracy']:.2f}%\")\n",
    "print(f\"Adjacent Accuracy: {results['adjacent_accuracy']:.2f}%\")\n",
    "print(f\"Per-Class Accuracy: {results['per_class_accuracy']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
