{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "transform_color = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_affine = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def angle_to_vector(theta_deg):\n",
    "    theta_rad = math.radians(theta_deg)\n",
    "    return torch.tensor([math.cos(theta_rad), math.sin(theta_rad)], dtype=torch.float32)\n",
    "\n",
    "def vector_to_angle(vector):\n",
    "    cos_theta, sin_theta = vector\n",
    "    angle_rad = torch.atan2(sin_theta, cos_theta)\n",
    "    angle_deg = angle_rad * (180 / math.pi)\n",
    "    # Ensure angle is in [0, 360) range\n",
    "    return (angle_deg + 360) % 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatitudeDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df, transform=None, scaler=None, fit_scaler=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        \n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            if fit_scaler:\n",
    "                self.scaler.fit(labels_df['latitude'].values.reshape(-1, 1))\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            \n",
    "        latitudes = labels_df['latitude'].values.reshape(-1, 1)\n",
    "        self.scaled_latitudes = self.scaler.transform(latitudes).flatten()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert to a PyTorch tensor with float32 dtype\n",
    "        scaled_latitude = torch.tensor(self.scaled_latitudes[idx], dtype=torch.float32)\n",
    "        \n",
    "        return image, scaled_latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extend Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(image_dir, labels_df):\n",
    "    # Original dataset\n",
    "    original_dataset = LatitudeDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_base\n",
    "    )\n",
    "    \n",
    "    # Color jitter augmented dataset\n",
    "    color_dataset = LatitudeDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_color\n",
    "    )\n",
    "    \n",
    "    # # Affine transform augmented dataset\n",
    "    affine_dataset = LatitudeDataset(\n",
    "        image_dir=image_dir,\n",
    "        labels_df=labels_df,\n",
    "        transform=transform_affine\n",
    "    )\n",
    "    \n",
    "    extended_dataset = ConcatDataset([original_dataset, color_dataset, affine_dataset])\n",
    "    \n",
    "    return original_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = \"Dataset/Train/images_train\"\n",
    "labels_path_train = \"Dataset/Train/labels_train.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(labels_path_train)\n",
    "\n",
    "train_dataset = create_extended_dataset(image_dir_train, labels_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_val = \"Dataset/Val/images_val\"\n",
    "labels_path_val = \"Dataset/Val/labels_val.csv\"\n",
    "labels_df_val = pd.read_csv(labels_path_val)\n",
    "\n",
    "val_dataset = LatitudeDataset(images_dir_val, labels_df_val, transform_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAngleRegressor(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet50(weights='DEFAULT' if pretrained else None)\n",
    "        num_features = base_model.fc.in_features\n",
    "        # Remove the final fully connected layer\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        \n",
    "        # New regression head with dropout and batch normalization\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.BatchNorm1d(1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.regressor(x)\n",
    "        # Normalize output to enforce unit vector\n",
    "        return x / torch.norm(x, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        y_pred_normalized = y_pred / torch.norm(y_pred, dim=1, keepdim=True)\n",
    "        y_true_normalized = y_true / torch.norm(y_true, dim=1, keepdim=True)\n",
    "        \n",
    "        cos_angle_diff = torch.sum(y_pred_normalized * y_true_normalized, dim=1)\n",
    "        \n",
    "        cos_angle_diff = torch.clamp(cos_angle_diff, -1.0 + 1e-7, 1.0 - 1e-7)\n",
    "        \n",
    "        angle_loss = 1.0 - cos_angle_diff\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return angle_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return angle_loss.sum()\n",
    "        else:\n",
    "            return angle_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(model, train_loader, val_loader, optimizer, num_epochs, device, loss_fn):\n",
    "   model.to(device)\n",
    "   best_val_loss = float('inf')\n",
    "\n",
    "   for epoch in range(num_epochs):\n",
    "       model.train()\n",
    "       train_loss = 0.0\n",
    "       pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "       for images, targets in pbar:\n",
    "           images = images.to(device)\n",
    "           targets = targets.to(device)\n",
    "\n",
    "           preds = model(images)\n",
    "           loss = loss_fn(preds.squeeze(), targets)\n",
    "\n",
    "           optimizer.zero_grad()\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "\n",
    "           train_loss += loss.item() * images.size(0)\n",
    "           pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "       avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "       # Validation loop\n",
    "       model.eval()\n",
    "       val_loss = 0.0\n",
    "       all_preds = []\n",
    "       all_targets = []\n",
    "       \n",
    "       with torch.no_grad():\n",
    "           pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "           for images, targets in pbar:\n",
    "               images = images.to(device)\n",
    "               targets = targets.to(device)\n",
    "\n",
    "               preds = model(images)\n",
    "               loss = loss_fn(preds.squeeze(), targets)\n",
    "\n",
    "               val_loss += loss.item() * images.size(0)\n",
    "               pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "       avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "       if avg_val_loss < best_val_loss:\n",
    "           best_val_loss = avg_val_loss\n",
    "           torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "       print(f\"Epoch {epoch+1}: Train MSE = {avg_train_loss:.4f}, Val MSE = {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, scaler):\n",
    "    model.eval()\n",
    "    scaled_predictions = []\n",
    "    scaled_ground_truths = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, scaled_latitudes in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            scaled_latitudes = scaled_latitudes.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            scaled_predictions.extend(outputs.cpu().numpy())\n",
    "            scaled_ground_truths.extend(scaled_latitudes.cpu().numpy())\n",
    "    \n",
    "    scaled_predictions = np.array(scaled_predictions)\n",
    "    scaled_ground_truths = np.array(scaled_ground_truths)\n",
    "    \n",
    "    scaled_mse = np.mean((scaled_predictions - scaled_ground_truths) ** 2)\n",
    "    \n",
    "    unscaled_predictions = scaler.inverse_transform(scaled_predictions.reshape(-1, 1)).flatten()\n",
    "    unscaled_ground_truths = scaler.inverse_transform(scaled_ground_truths.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    unscaled_mse = np.mean((unscaled_predictions - unscaled_ground_truths) ** 2)\n",
    "    \n",
    "    results = {\n",
    "        'scaled_mse': scaled_mse,\n",
    "        'unscaled_mse': unscaled_mse,\n",
    "        'scaled_predictions': scaled_predictions,\n",
    "        'scaled_ground_truths': scaled_ground_truths,\n",
    "        'unscaled_predictions': unscaled_predictions,\n",
    "        'unscaled_ground_truths': unscaled_ground_truths\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|██████████| 409/409 [01:56<00:00,  3.52it/s, loss=1.01] \n",
      "Epoch 1/50 [Val]:  96%|█████████▌| 23/24 [00:02<00:00,  6.38it/s, loss=0.894]/home/chetan/miniconda3/envs/localEnv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1/50 [Val]: 100%|██████████| 24/24 [00:02<00:00,  8.14it/s, loss=0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE = 1.9939, Val MSE = 2.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]:  23%|██▎       | 94/409 [00:27<01:33,  3.37it/s, loss=1.01] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m loss_fn = nn.MSELoss()\n\u001b[32m      3\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m1e-6\u001b[39m, weight_decay=\u001b[32m1e-5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrain_regression_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain_regression_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, num_epochs, device, loss_fn)\u001b[39m\n\u001b[32m     15\u001b[39m loss = loss_fn(preds.squeeze(), targets)\n\u001b[32m     17\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m optimizer.step()\n\u001b[32m     21\u001b[39m train_loss += loss.item() * images.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/localEnv/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/localEnv/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/localEnv/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = ResNetAngleRegressor()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=1e-5)\n",
    "train_regression_model(model, train_loader, val_loader, optimizer, num_epochs=50, device=device, loss_fn=loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Angle Error: 31.3410 degrees\n",
      "Median Angle Error: 20.2693 degrees\n",
      "MSE (sin/cos): 0.4838\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = evaluate_model(model, val_loader, device)\n",
    "print(\"Scaled MSE:\", results['scaled_mse'])\n",
    "print(\"Unscaled MSE:\", results['unscaled_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Angle Error: 30.8790 degrees\n",
      "Median Angle Error: 19.3219 degrees\n",
      "MSE (sin/cos): 0.4744\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for evaluation\n",
    "\n",
    "model_ev = ResNetAngleRegressor()\n",
    "model_ev.to(device)\n",
    "model_ev.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "results = evaluate_model(model_ev, val_loader, device)\n",
    "print(f\"Mean Angle Error: {results['mean_angle_error']:.4f} degrees\")\n",
    "print(f\"Median Angle Error: {results['median_angle_error']:.4f} degrees\")\n",
    "print(f\"MSE (sin/cos): {results['mse_sin_cos']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
